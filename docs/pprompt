根据如描述说明，帮我编写一款简单的AI对话页面。
        1. 请编写html、js、tailwindcss UI 效果。不要写react、vue。
        2. 点击新建聊天，会创建一个新的加入左侧的聊天列表
        3. 聊天列表可以点击展开选择。
        4. 选择的聊天，在对话列表中，可以点击删除或者重命名。
        5. 输入内容，点击发送按钮和使用快捷键，调用服务端流式请求接口，前端渲染展示。
        6. 以html、js代码方式实现，css样式使用 tailwind 编写。
        7. 通过 const eventSource = new EventSource(apiUrl); 调用api接口。
        8. 从 result.output.text 获取，应答的文本展示。注意 text 可能为空。
        9. 从 result.metadata.finishReason = stop 获取结束标识。
        10. 注意整体样式的简洁美观。

        接口信息如下

        流式POST请求接口，由 SpringBoot Spring AI 框架实现，如下；

/**
 * curl http://localhost:8089/api/v1/ollama/generate_stream_rag?model=qwen3:1.7b&ragTag=DBGPT知识库&message=hi
 */
    @RequestMapping(value = "generate_stream_rag", method = RequestMethod.POST)
    public Flux<ChatResponse> generateStreamRag(@RequestParam String model, @RequestParam String ragTag, @RequestParam String message) {
        String SYSTEM_PROMPT = """
                基于以下给出的 DOCUMENTS 信息，遵守规范约束，专业、简要回答用户的问题。
                规范约束:
                1. 如果已知信息包含图片、链接、表格、代码块等特殊markdown标签格式的信息，确保在答案中包含原文这些标签，不要丢弃或修改。
                   如: 图片格式：![image.png](xxx), 链接格式:[xxx](xxx), 表格格式:|xxx|xxx|xxx|, 代码格式:```xxx```
                2. 如果无法从提供的内容中获取答案，请回答: "知识库中提供的内容不足以回答此问题"，禁止编造答案。
                3. 回答时最好按照1.2.3.点进行总结，并以markdown格式显示。
                4. 请使用与用户相同的语言进行回答。
                DOCUMENTS:
                {documents}""";
        try {
            // 参数校验
            if (StringUtils.isBlank(model) || StringUtils.isBlank(ragTag) || StringUtils.isBlank(message)) {
                return Flux.error(new IllegalArgumentException("模型名称、知识库标签和消息内容不能为空"));
            }

            log.info("开始处理RAG请求 - 模型: {}, 标签: {}, 消息: {}", model, ragTag, message);

            // 1. 构建搜索请求并获取文档
            SearchRequest request = SearchRequest.builder()
                    .query(message)
                    .topK(5)
                    .filterExpression("knowledge == '" + ragTag + "'")
                    .build();

            List<Document> documents;
            try {
                documents = pgVectorStore.similaritySearch(request);
            } catch (Exception e) {
                log.error("知识库搜索失败", e);
                return Flux.error(new RuntimeException("知识库搜索失败，请稍后重试"));
            }

            // 2. 检查知识库是否为空
            if (documents == null || documents.isEmpty()) {
                Document emptyDocument = new Document("知识库中未找到相关内容，请直接返回无法回答问题的内容");
                documents = List.of(emptyDocument);
            }

            // 3. 合并文档内容
            String documentsContent;
            try {
                documentsContent = documents.stream()
                        .map(Document::getText)
                        .collect(Collectors.joining());
            } catch (Exception e) {
                log.error("文档内容合并失败", e);
                return Flux.error(new RuntimeException("文档处理失败，请稍后重试"));
            }

            // 4. 构建消息列表
            List<Message> messages;
            try {
                messages = Arrays.asList(
                        new UserMessage(message),
                        new SystemPromptTemplate(SYSTEM_PROMPT)
                                .createMessage(Map.of("documents", documentsContent))
                );
            } catch (Exception e) {
                log.error("消息构建失败", e);
                return Flux.error(new RuntimeException("消息构建失败，请稍后重试"));
            }
            log.info("消息列表: {}", JSON.toJSONString(messages));
            // 5. 调用模型并返回响应
            try {
                return ollamaChatModel.stream(new Prompt(messages,
                                OllamaOptions.builder()
                                        .model(model)
                                        .build())
                        )
                        .onErrorResume(e -> {
                            log.error("模型响应生成失败", e);
                            return Flux.error(new RuntimeException("生成回答时出错，请稍后重试"));
                        });
            } catch (Exception e) {
                log.error("模型调用失败", e);
                return Flux.error(new RuntimeException("模型服务不可用，请稍后重试"));
            }

        } catch (Exception e) {
            log.error("处理RAG请求时发生未预期错误", e);
            return Flux.error(new RuntimeException("系统繁忙，请稍后重试"));
        }
    }

        流式GET应答数据，数组中的部分对象；
[
    {
        "result": {
            "metadata": {
                "finishReason": null,
                "contentFilters": [],
                "empty": true
            },
            "output": {
                "messageType": "ASSISTANT",
                "metadata": {
                    "messageType": "ASSISTANT"
                },
                "toolCalls": [],
                "media": [],
                "text": "对"
            }
        },
        "metadata": {
            "id": "",
            "model": "qwen3:1.7b",
            "rateLimit": {
                "requestsRemaining": 0,
                "requestsLimit": 0,
                "tokensRemaining": 0,
                "tokensReset": "PT0S",
                "requestsReset": "PT0S",
                "tokensLimit": 0
            },
            "usage": {
                "promptTokens": 0,
                "completionTokens": 0,
                "totalTokens": 0,
                "generationTokens": 0
            },
            "promptMetadata": [],
            "empty": false
        },
        "results": [
            {
                "metadata": {
                    "finishReason": null,
                    "contentFilters": [],
                    "empty": true
                },
                "output": {
                    "messageType": "ASSISTANT",
                    "metadata": {
                        "messageType": "ASSISTANT"
                    },
                    "toolCalls": [],
                    "media": [],
                    "text": "问题"
                }
            }
        ]
    },
    {
        "result": {
            "metadata": {
                "finishReason": null,
                "contentFilters": [],
                "empty": true
            },
            "output": {
                "messageType": "ASSISTANT",
                "metadata": {
                    "messageType": "ASSISTANT"
                },
                "toolCalls": [],
                "media": [],
                "text": "。"
            }
        },
        "metadata": {
            "id": "",
            "model": "qwen3:1.7b",
            "rateLimit": {
                "requestsRemaining": 0,
                "requestsLimit": 0,
                "tokensRemaining": 0,
                "tokensReset": "PT0S",
                "requestsReset": "PT0S",
                "tokensLimit": 0
            },
            "usage": {
                "promptTokens": 0,
                "completionTokens": 0,
                "totalTokens": 0,
                "generationTokens": 0
            },
            "promptMetadata": [],
            "empty": false
        },
        "results": [
            {
                "metadata": {
                    "finishReason": null,
                    "contentFilters": [],
                    "empty": true
                },
                "output": {
                    "messageType": "ASSISTANT",
                    "metadata": {
                        "messageType": "ASSISTANT"
                    },
                    "toolCalls": [],
                    "media": [],
                    "text": "。"
                }
            }
        ]
    },
    {
        "result": {
            "metadata": {
                "finishReason": "stop",
                "contentFilters": [],
                "empty": true
            },
            "output": {
                "messageType": "ASSISTANT",
                "metadata": {
                    "messageType": "ASSISTANT"
                },
                "toolCalls": [],
                "media": [],
                "text": ""
            }
        },
        "metadata": {
            "id": "",
            "model": "qwen3:1.7b",
            "rateLimit": {
                "requestsRemaining": 0,
                "requestsLimit": 0,
                "tokensRemaining": 0,
                "tokensReset": "PT0S",
                "requestsReset": "PT0S",
                "tokensLimit": 0
            },
            "usage": {
                "promptTokens": 202,
                "completionTokens": 104,
                "totalTokens": 306,
                "generationTokens": 104
            },
            "promptMetadata": [],
            "empty": false
        },
        "results": [
            {
                "metadata": {
                    "finishReason": "stop",
                    "contentFilters": [],
                    "empty": true
                },
                "output": {
                    "messageType": "ASSISTANT",
                    "metadata": {
                        "messageType": "ASSISTANT"
                    },
                    "toolCalls": [],
                    "media": [],
                    "text": ""
                }
            }
        ]
    }
]